# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AQ7Ve1XyxwaaQk1hT3M8JEvHOx5PiN_0
"""

# Importation des bibliothèques
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from keras.models import Sequential
from keras.layers import Dense, Dropout
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Chargement des données
from sklearn.datasets import fetch_openml
print("Chargement des données...")
data = fetch_openml('creditcard')
X = data.data
y = data.target.astype('int')

# 2. Préparation des données
# Standardisation
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split des données
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Modèle de base (sans SMOTE)
model_base = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

model_base.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 4. Entraînement modèle de base
history_base = model_base.fit(X_train, y_train,
                            epochs=10,
                            batch_size=128,
                            validation_split=0.2,
                            verbose=1)

# 5. Application de SMOTE
smote = SMOTE(random_state=42)
X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)

# 6. Modèle avec SMOTE
model_smote = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

model_smote.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 7. Entraînement modèle SMOTE
history_smote = model_smote.fit(X_train_sm, y_train_sm,
                               epochs=10,
                               batch_size=128,
                               validation_split=0.2,
                               verbose=1)

# 8. Évaluation des deux modèles
def evaluate_model(model, X_test, y_test, title):
    y_pred = (model.predict(X_test) > 0.5).astype("int32")
    print(f"\nRésultats pour {title}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # Matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8,6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Matrice de Confusion - {title}')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

evaluate_model(model_base, X_test, y_test, "Modèle de Base")
evaluate_model(model_smote, X_test, y_test, "Modèle avec SMOTE")